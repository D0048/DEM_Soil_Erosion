{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, random, string\n",
    "import os, sys\n",
    "from h5py import File\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing\n",
    "%matplotlib notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed()\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: (5028, 6, 128, 128)\n",
      "labels: (5028, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/d0048/Desktop/hackerson/hackII\"\n",
    "img_paths=[file for file in glob.glob(path + \"/all_frames_5m6b/*.npy\")]\n",
    "img_paths.sort()\n",
    "label_paths=[file for file in glob.glob(path + \"/all_masks_5m6b/*.npy\")]\n",
    "label_paths.sort()\n",
    "images = np.asarray([np.load(pth) for pth in img_paths]).transpose([0,3,1,2])\n",
    "labels = np.asarray([np.load(pth) for pth in label_paths]).astype(np.double)\n",
    "\n",
    "print('images: {}'.format(images.shape))\n",
    "print('labels: {}'.format(labels.shape))\n",
    "plt.imshow(images[100,:,:,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dconv_down1 = double_conv(6, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(\n",
    "            scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=UNet(1)\n",
    "model.train()\n",
    "y=model(torch.Tensor(images[0:2,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Loss: 3.221248399347194\n",
      "Step: 2, Loss: 0.4491828699514317\n",
      "Step: 3, Loss: 1.0787694526564264\n",
      "Step: 4, Loss: 1.0745441796987094\n",
      "Step: 5, Loss: 0.2711768017660552\n",
      "Step: 6, Loss: 0.2249392209993741\n",
      "Step: 7, Loss: 0.49947446009579427\n",
      "Step: 8, Loss: 0.39719790977556635\n",
      "Step: 9, Loss: 0.2645301066110153\n",
      "Step: 10, Loss: 0.0944639327547864\n",
      "Step: 11, Loss: 0.08860555275370266\n",
      "Step: 12, Loss: 0.2318749972933029\n",
      "Step: 13, Loss: 0.210039647086326\n",
      "Step: 14, Loss: 0.14065784458245525\n",
      "Step: 15, Loss: 0.05437015472806108\n",
      "Step: 16, Loss: 0.07251023857706412\n",
      "Step: 17, Loss: 0.12131261691744706\n",
      "Step: 18, Loss: 0.1013093933563589\n",
      "Step: 19, Loss: 0.0498976458437554\n",
      "Step: 20, Loss: 0.0352788786740853\n",
      "Step: 21, Loss: 0.027406247886418836\n",
      "Step: 22, Loss: 0.057380803930791244\n",
      "Step: 23, Loss: 0.06340820255244273\n",
      "Step: 24, Loss: 0.0426581617238797\n",
      "Step: 25, Loss: 0.023425501234415086\n",
      "Step: 26, Loss: 0.03348186611335784\n",
      "Step: 27, Loss: 0.02782358790920025\n",
      "Step: 28, Loss: 0.05292712420870593\n",
      "Step: 29, Loss: 0.06242852826268783\n",
      "Step: 30, Loss: 0.03489452252708426\n",
      "Step: 31, Loss: 0.01711042590821486\n",
      "Step: 32, Loss: 0.04035060210943783\n",
      "Step: 33, Loss: 0.051855872756557245\n",
      "Step: 34, Loss: 0.04633252631846356\n",
      "Step: 35, Loss: 0.026922241038055884\n",
      "Step: 36, Loss: 0.04728803796606776\n",
      "Step: 37, Loss: 0.01988223714870843\n",
      "Step: 38, Loss: 0.022181224698995798\n",
      "Step: 39, Loss: 0.012924033547659112\n",
      "Step: 40, Loss: 0.01252509837044801\n",
      "Step: 41, Loss: 0.03932816157445617\n",
      "Step: 42, Loss: 0.016749615085460592\n",
      "Step: 43, Loss: 0.013359624167579546\n",
      "Step: 44, Loss: 0.012701309219704039\n",
      "Step: 45, Loss: 0.03596362047566204\n",
      "Step: 46, Loss: 0.008576123350414314\n",
      "Step: 47, Loss: 0.014075909411241564\n",
      "Step: 48, Loss: 0.017572763013031057\n",
      "Step: 49, Loss: 0.014293638311291927\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2d8e4fda34c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step: {}, Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "my_dataset = torch.utils.data.TensorDataset(torch.tensor(images),torch.tensor(labels)) # create your datset\n",
    "my_dataloader = torch.utils.data.DataLoader(my_dataset,batch_size=batch_size) # create your dataloader\n",
    "\n",
    "e=0\n",
    "for x,label in my_dataloader:\n",
    "    e+=1\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x).squeeze()\n",
    "\n",
    "    pred=pred.double()\n",
    "    \n",
    "    loss = criterion(pred, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Step: {}, Loss: {}'.format(e,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
